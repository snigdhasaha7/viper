dataset:
    data_path: sample_okvqa500
    dataset_name: OKVQA
    split: test
    testing: False
    max_samples: 500
    batch_size: 1
    start_sample: 0

codex:
    temperature: 1.0                            # Temperature for Codex. (Almost) deterministic if 0
    top_p: 0.95                               # Top p for Codex
    best_of: 1                                      # Number of tries to choose from. Use when temperature > 0
    max_tokens: 1024                                 # Maximum number of tokens to generate for Codex
    prompt: ./prompts/chatapi.prompt                # Codex prompt file, which defines the API. (doesn't support video for now due to token limits)
    model: gpt-4o                          # Codex model to use. [code-davinci-002, gpt-3.5-turbo, gpt-4]. See openai.Model.list() for available models
    num_outputs: 5

results_dir: ./results/okvqav2/

load_models:
    maskrcnn: True
    clip: False
    glip: True
    owlvit: False
    tcl: False
    gpt3_list: True
    gpt3_qa: True
    gpt3_guess: True
    depth: True
    blip: True
    saliency: False
    xvlm: True

fixed_code_file: ./prompts/fixed_code/blip2.prompt