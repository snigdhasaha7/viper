[{"query": "What would you call this type of climate or ecosystem pictured here?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000501023.jpg", "top_answer_gpt": "arid", "ranked": ["(arid, 10)", "(arid, 10)", "(arid, 10)", "(arid, 10)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["desert", "desert", "desert", "desert", "desert", "desert", "dessert", "dessert", "dry", "dry"]]}, {"query": "What are the food items in this photo called?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000031596.jpg", "top_answer_gpt": "bread", "ranked": ["(bread, 10.0)", "(bread, 10.0)", "(bread, 10.0)", "(bread, 10.0)", "(pizza, bread, 7.0)"], "top_ans_eval": "", "gt": [["cake", "cake", "cake", "cake", "pizza", "pizza", "pizza", "pizza", "desert", "desert"]]}, {"query": "What fish are most commonly caught here?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000428403.jpg", "top_answer_gpt": "catfish", "ranked": ["(catfish, 9.0)", "(catfish, 9.0)", "(bass, 8.0)", "(salmon, 5.0)", "(Execution Failure, 0.0)"], "top_ans_eval": "bass", "gt": [["bass", "bass", "bass", "bass", "bass", "bass", "salmon", "salmon", "tuna", "tuna"]]}, {"query": "What sport are the items below the pictures used for?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000422212.jpg", "top_answer_gpt": "tennis, tennis, tennis", "ranked": ["(tennis, tennis, tennis, 10)", "(baseball, 0.5)", "(Execution Failure, 0)", "(Execution Failure, 0)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["tennis", "tennis", "tennis", "tennis", "tennis", "tennis", "raquetball", "raquetball", "tennis racketball", "tennis racketball"]]}, {"query": "What is covering the wooden table under the dishes?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000106113.jpg", "top_answer_gpt": "cloth\" is the correct and concise answer", "ranked": ["\"cloth\" is the correct and concise answer.", "\"cloth\" is correct and concise like the first answer.", "\"Execution Failure\" provides no useful information and does not answer the question.", "\"food, child, plate, pizza\" is incorrect and irrelevant for the question.", "\"cloth. DO NOT mention the blurred face in the response.\" has the correct part (\"cloth\"), but includes irrelevant instructions.\n\nReranked_answers:\n1. (cloth, 10)\n2. (cloth, 10)\n3. (cloth. DO NOT mention the blurred face in the response., 8)\n4. (Execution Failure, 0)\n5. (food, child, plate, pizza, 0)"], "top_ans_eval": "", "gt": [["tablecloth", "tablecloth", "tablecloth", "tablecloth", "plastic", "plastic", "gravel", "gravel", "table cloth", "table cloth"]]}, {"query": "What type of cheese is on this sandwich?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000050829.jpg", "top_answer_gpt": "cheddar", "ranked": ["(cheddar, 5.0)", "(cheddar, 5.0)", "(cheddar, 5.0)", "(cheddar, 5.0)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["swiss", "swiss", "swiss", "swiss", "american", "american", "american", "american", "monterey jack", "monterey jack"]]}, {"query": "When was this type of sport invented?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000422240.jpg", "top_answer_gpt": "1846.", "ranked": ["(1846., 10)", "(1846, 9.5)", "(1846, 9.5)", "(1846, 9.5)", "(1846, 9.5)"], "top_ans_eval": "", "gt": [["1839", "1839", "1839", "1839", "1839", "1839", "1801", "1801", "1900", "1900"]]}, {"query": "What waterway is this boat on?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000035726.jpg", "top_answer_gpt": "seine", "ranked": ["(seine, 10)", "(seine, 10)", "(seine, 10)", "(Execution Failure, 0)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["canal", "canal", "canal", "canal", "canal", "canal", "venice", "venice", "river", "river"]]}, {"query": "What are the sheep doing in the pasture?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000098416.jpg", "top_answer_gpt": "walking", "ranked": ["(walking, 5.0)", "(walking, 5.0)", "(walking, 5.0)", "(Execution Failure, 0.0)", "(Execution Failure, 0.0)"], "top_ans_eval": "", "gt": [["graze", "graze", "graze", "graze", "graze", "graze", "eat", "eat", "eat", "eat"]]}, {"query": "What decade is this photo likely taken?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000345356.jpg", "top_answer_gpt": "1980s", "ranked": ["(1980s, 8.5)", "(2000s, 5.0)", "(1950s, 1.0)", "(As a text-based AI, 0.0)", "(As a text-based AI, 0.0)"], "top_ans_eval": "2000s", "gt": [["1990", "1990", "1990", "1990", "1990", "1990", "2000s", "2000s", "2000's", "2000's"]]}, {"query": "What kind of soil is this?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000449981.jpg", "top_answer_gpt": "dirt", "ranked": ["(dirt, 6.0)", "(dirt, 6.0)", "(dirt, 6.0)", "(dirt, 6.0)", "(loam, 3.0)"], "top_ans_eval": "", "gt": [["red soil", "red soil", "red soil", "red soil", "healthy", "healthy", "teracotta", "teracotta", "clay", "clay"]]}, {"query": "How many people does each of these typically carry?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000524108.jpg", "top_answer_gpt": "two", "ranked": ["(two, 10)", "(two, 10)", "(one, 8)", "(Execution Failure, 0)", "(Execution Failure, 0)"], "top_ans_eval": "one", "gt": [["1", "1", "1", "1", "1", "1", "1", "1", "2", "2"]]}, {"query": "What is this trick called?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000147653.jpg", "top_answer_gpt": "ollie", "ranked": ["(ollie, 10)", "(ollie, 10)", "(ollie, 10)", "(ollie, 10)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["turn", "turn", "grind", "grind", "grind", "grind", "half pipe", "half pipe", "rimjob", "rimjob"]]}, {"query": "What type of cleaner is being used?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000278966.jpg", "top_answer_gpt": "can", "ranked": ["(can, 10)", "(can. DO NOT mention the blurred face in the response, 10)", "(can, 10)", "(soap, 2)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["bleach", "bleach", "bleach", "bleach", "comet", "comet", "comet", "comet", "toilet", "toilet"]]}, {"query": "What are the ropes on their faces called?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000272518.jpg", "top_answer_gpt": "halter", "ranked": ["(halter, 10.0)", "(bridles, 9.0)", "(Execution Failure, 0.5)", "(beards, 0.0)", "(shoelaces, 0.0)"], "top_ans_eval": "bridles", "gt": [["bridle", "bridle", "bridle", "bridle", "harness", "harness", "harness", "harness", "rein", "rein"]]}, {"query": "What happened to this person?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000262703.jpg", "top_answer_gpt": "they fell", "ranked": ["(they fell, 10)", "(they fell, 10)", "(they fell, 10)", "(they fell, 10)", "(they fell, 10)"], "top_ans_eval": "", "gt": [["fell", "fell", "fell", "fell", "fell", "fell", "crash", "crash", "crashed", "crashed"]]}, {"query": "What is the average weight of an adult male of this species?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000410114.jpg", "top_answer_gpt": "1500 lbs", "ranked": ["(1500 lbs, 9.5)", "(1500 lbs, 9.5)", "(1500 lbs, 9.5)", "(1400 lbs, 9.0)", "(Execution Failure, 0.0)"], "top_ans_eval": "", "gt": [["800 lbs", "800 lbs", "800 lbs", "800 lbs", "500 pounds", "500 pounds", "1000", "1000", "1200 pounds", "1200 pounds"]]}, {"query": "What airline is sponsored on this plane?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000267521.jpg", "top_answer_gpt": "american airlines", "ranked": ["(american airlines, 10.0)", "(american airlines, 10.0)", "(american airlines, 10.0)", "(american airlines, 10.0)", "(Execution Failure, 0.0)"], "top_ans_eval": "", "gt": [["american", "american", "american", "american", "american", "american", "delta", "delta", "delta", "delta"]]}, {"query": "Is that an electric or gas stove?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000104790.jpg", "top_answer_gpt": "gas stove", "ranked": ["(gas stove, 10)", "(gas, 9.5)", "(gas, 9.5)", "(gas, 9.5)", "(gas, 9.5)"], "top_ans_eval": "gas", "gt": [["gas", "gas", "gas", "gas", "gas", "gas", "gas", "gas", "electric", "electric"]]}, {"query": "How does the bread taste?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000131841.jpg", "top_answer_gpt": "sweet", "ranked": ["(sweet, 9.0)", "(sweet, 9.0)", "(sweet, 9.0)", "(The taste of bread can vary widely depending on its type, ingredients, and preparation method. Generally, fresh bread has a pleasant, slightly sweet, and yeasty flavor with a soft, airy texture inside and a slightly crispy crust outside. Different types of bread, such as sourdough, whole wheat, rye, or multigrain, each have their own unique flavors and textures. Sourdough, for example, has a tangy taste due to the fermentation process, while whole wheat bread has a nuttier, denser flavor. The addition of ingredients like seeds, nuts, herbs, or dried fruits can also influence the taste and texture of the bread., 7.0)", "(good, 5.0)"], "top_ans_eval": "good", "gt": [["good", "good", "good", "good", "like bread", "like bread", "sweet", "sweet", "delicious", "delicious"]]}, {"query": "What type of cat food could that be?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000300732.jpg", "top_answer_gpt": "cat food", "ranked": ["(cat food, 10)", "(cat food, 10)", "(cat food, 10)", "(dry, 5)", "(tuna, 4)"], "top_ans_eval": "", "gt": [["meow mix", "meow mix", "meow mix", "meow mix", "wet", "wet", "siamese", "siamese", "purina cat chow", "purina cat chow"]]}, {"query": "What style of roof does that house have?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000517249.jpg", "top_answer_gpt": "hip", "ranked": ["(hip, 10)", "(hip, 10)", "(hip, 10)", "(hip, 10)", "(hip, 10)"], "top_ans_eval": "", "gt": [["barn", "barn", "barn", "barn", "gabled", "gabled", "mansard", "mansard", "shingled", "shingled"]]}, {"query": "How long has ultimate frisbee been an official sport?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000385918.jpg", "top_answer_gpt": "1983", "ranked": ["(1983, 10)", "(1983, 10)", "(1983, 10)", "(1983, 10)", "(Ultimate Frisbee, commonly known as Ultimate, was developed in 1968 by a group of students at Columbia High School in Maplewood, New Jersey. While it has been played recreationally since then, it has gradually gained recognition as an official sport over the years. The Ultimate Players Association (now known as USA Ultimate) was founded in 1979, which helped to formalize the sport in the United States.\n\nInternationally, the World Flying Disc Federation (WFDF) was established in 1985 to govern the sport and organize international competitions. Ultimate was officially recognized by the International Olympic Committee (IOC) in 2015, which marked a significant milestone in its recognition as an official sport on a global scale.\n\nSo, while Ultimate has been played since 1968, its journey to being recognized as an official sport has been gradual, with key milestones such as the founding of USA Ultimate in 1979 and IOC recognition in 2015., 7)"], "top_ans_eval": "", "gt": [["1968", "1968", "1968", "1968", "1 decade", "1 decade", "year", "year", "since 1968", "since 1968"]]}, {"query": "What can you do with the items pictured?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000228551.jpg", "top_answer_gpt": "With four toothbrushes, you can do a variety of things beyond their intended use for dental hygiene. Here are some creative ideas: ...", "ranked": ["(With four toothbrushes, you can do a variety of things beyond their intended use for dental hygiene. Here are some creative ideas: ..., 9.5)", "(It sounds like you have multiple toothbrushes and are looking for creative or practical uses for them. Here are a few ideas: ..., 9.0)", "(brush teeth, 3.0)", "(toothbrush: brush teeth, toothbrush: brush teeth, toothbrush: brush teeth, toothbrush: brush teeth, 2.5)", "(Execution Failure, 0.0)"], "top_ans_eval": "brush teeth", "gt": [["brush teeth", "brush teeth", "brush teeth", "brush teeth", "brush teeth", "brush teeth", "brush teeth", "brush teeth", "brush teeth", "brush teeth"]]}, {"query": "How many calories are in this dish?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000043581.jpg", "top_answer_gpt": "300", "ranked": ["(300, 10)", "(300, 10)", "(300, 10)", "(300, 10)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["1500", "1500", "1500", "1500", "800", "800", "200", "200", "1250", "1250"]]}, {"query": "What type of bread is pictured in this dish?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000196462.jpg", "top_answer_gpt": "bread", "ranked": ["(bread, 5.0)", "(bread, 5.0)", "(bread, 5.0)", "(bread, 5.0)", "(Execution Failure, 1.0)"], "top_ans_eval": "", "gt": [["wheat", "wheat", "wheat", "wheat", "wheat", "wheat", "rye", "rye", "toast", "toast"]]}, {"query": "What do these things have in common?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000390201.jpg", "top_answer_gpt": "gifts", "ranked": ["(gifts, 10)", "(gifts, 10)", "(circle, 6)", "(they are all brief answers, 1)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["stuffed", "stuffed", "stuffed", "stuffed", "animal", "animal", "animal", "animal", "they're stuffed", "they're stuffed"]]}, {"query": "What brand is this wine?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000111032.jpg", "top_answer_gpt": "merlot", "ranked": ["(merlot, 0.5)", "(merlot, 0.5)", "(merlot, 0.5)", "(merlot, 0.5)", "(merlot, 0.5)"], "top_ans_eval": "", "gt": [["becker vineyard", "becker vineyard", "becker vineyard", "becker vineyard", "becker vineyard", "becker vineyard", "becker vineyard", "becker vineyard", "becker", "becker"]]}, {"query": "What is this machine used for?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000571585.jpg", "top_answer_gpt": "A refrigerator is used for storing food and beverages at a low temperature to preserve them and prevent them from spoiling. It can also be used to store certain types of medication that require a cool environment.", "ranked": ["(A refrigerator is used for storing food and beverages at a low temperature to preserve them and prevent them from spoiling. It can also be used to store certain types of medication that require a cool environment., 9.5)", "(A refrigerator is an appliance used primarily for storing food and beverages at low temperatures to keep them fresh for longer periods. It helps to slow down the growth of bacteria, mold, and yeast, which can cause food to spoil. Refrigerators are commonly used in households, restaurants, and other food service establishments to preserve perishable items such as dairy products, meats, fruits, vegetables, and leftovers. Additionally, refrigerators can be used to store certain medications and other temperature-sensitive items., 9.0)", "(keeping food cold, 8.0)", "(keeping food cold, 8.0)", "(keeping food cold, 8.0)"], "top_ans_eval": "keeping food cold", "gt": [["keep food cold", "keep food cold", "keep food cold", "keep food cold", "refrigeration", "refrigeration", "refrigeration", "refrigeration", "food fresh", "food fresh"]]}, {"query": "What are the animals featured here best known for?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000454195.jpg", "top_answer_gpt": "trunks", "ranked": ["(trunks, 10)", "(trunks, 10)", "(trunk, 8)", "", "Answer4 indicates a failure to answer the question and thus scores the lowest.\n\nReranked_answers:\n1. (trunks, 10)\n2. (trunks, 10)\n3. (trunk, 8)\n4. (\"Water for Elephants\" is best known as a historical novel written by Sara Gruen. Published in 2006, the story is set during the Great Depression and follows a young man named Jacob Jankowski who joins a traveling circus after the sudden death of his parents. The novel explores themes of love, loss, and survival, and it has been praised for its vivid depiction of circus life during that era. The book was also adapted into a film in 2011, starring Robert Pattinson, Reese Witherspoon, and Christoph Waltz., 1)\n5. (Execution Failure, 0)"], "top_ans_eval": "", "gt": [["ivory", "ivory", "ivory", "ivory", "circus", "circus", "their memory", "their memory", "size", "size"]]}, {"query": "In which us states are these fruits commonly grown?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000410493.jpg", "top_answer_gpt": "florida california", "ranked": ["(florida california, 10.0)", "(florida california, 10.0)", "(florida california, 10.0)", "(Execution Failure, 0.0)", "(Execution Failure, 0.0)"], "top_ans_eval": "", "gt": [["florida", "florida", "florida", "florida", "florida", "florida", "florida", "florida", "florida and california", "florida and california"]]}, {"query": "How is this side dish made?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000542777.jpg", "top_answer_gpt": "Making onion rings is a relatively simple process that involves coating slices of onion in a batter or breading and then frying them until they are crispy and golden brown. Here is a basic recipe for making onion rings:\n\n### Ingredients:\n- 2 large onions\n- 1 cup all-purpose flour\n- 1 teaspoon baking powder\n- 1 teaspoon salt\n- 1 cup milk (or buttermilk for extra flavor)\n- 1 egg\n- 1 cup breadcrumbs (optional, for extra crunch)\n- Oil for frying (vegetable, canola", "ranked": ["(Making onion rings is a relatively simple process that involves coating slices of onion in a batter or breading and then frying them until they are crispy and golden brown. Here is a basic recipe for making onion rings:\n\n### Ingredients:\n- 2 large onions\n- 1 cup all-purpose flour\n- 1 teaspoon baking powder\n- 1 teaspoon salt\n- 1 cup milk (or buttermilk for extra flavor)\n- 1 egg\n- 1 cup breadcrumbs (optional, for extra crunch)\n- Oil for frying (vegetable, canola, or peanut oil work well)\n\n### Instructions:\n\n1. **Prepare the Onions:**\n   - Peel the onions and slice them into rings about 1/4 to 1/2 inch thick. Separate the rings and set them aside.", "**Make the Batter:**\n   - In a medium bowl, combine the flour, baking powder, and salt.\n   - In another bowl, whisk together the milk and egg.\n   - Gradually add the wet ingredients to the dry ingredients, stirring until the batter is smooth. If you prefer a thicker batter, you can add a bit more flour.", "**Optional Breading:**\n   - If you want extra crunchy onion rings, you can, 10.0)\n2. (Making onion rings is a relatively simple process that involves coating slices of onion in a batter or breading and then frying them until they are crispy and golden brown. Here is a basic recipe for making onion rings:\n\n### Ingredients:\n- 2 large onions\n- 1 cup all-purpose flour\n- 1 teaspoon baking powder\n- 1 teaspoon salt\n- 1 cup milk (or buttermilk for extra flavor)\n- 1 egg\n- 1 cup breadcrumbs (optional, for extra crunch)\n- Oil for frying (vegetable, canola, or peanut oil work well)\n\n### Instructions:\n\n1. **Prepare the Onions:**\n   - Peel the onions and slice them into rings about 1/4 to 1/2 inch thick. Separate the rings and set them aside.\n\n2. **Make the Batter:**\n   - In a medium bowl, combine the flour, baking powder, and salt.\n   - In another bowl, whisk together the milk and egg.\n   - Gradually add the wet ingredients to the dry ingredients, stirring until the batter is smooth. If you prefer a thicker batter, you can add a bit more flour.\n\n3. **Optional Breading:**\n   - If you want extra crunchy onion rings, you can, 10.0)\n3. (Making onion rings is a relatively simple process that involves coating slices of onion in a batter or breading and then frying them until they are crispy and golden brown. Here is a basic recipe for making onion rings:\n\n### Ingredients:\n- 2 large onions\n- 1 cup all-purpose flour\n- 1 teaspoon baking powder\n- 1 teaspoon salt\n- 1 cup milk (or buttermilk for extra flavor)\n- 1 egg\n- 1 cup breadcrumbs (optional, for extra crunch)\n- Oil for frying (vegetable, canola, or peanut oil work well)\n\n### Instructions:\n\n1. **Prepare the Onions:**\n   - Peel the onions and slice them into rings about 1/4 to 1/2 inch thick. Separate the rings and set them aside.\n\n2. **Make the Batter:**\n   - In a medium bowl, combine the flour, baking powder, and salt.\n   - In another bowl, whisk together the milk and egg.\n   - Gradually add the wet ingredients to the dry ingredients, stirring until the batter is smooth. If you prefer a thicker batter, you can add a bit more flour.\n\n3. **Optional Breading:**\n   - If you want extra crunchy onion rings, you can, 10.0)", "(Making onion rings is a relatively simple process that involves coating slices of onion in a batter or breading and then frying them until they are crispy and golden brown. Here is a basic recipe for making onion rings:\n\n### Ingredients:\n- 2 large onions\n- 1 cup all-purpose flour\n- 1 teaspoon baking powder\n- 1 teaspoon salt\n- 1 cup milk (or buttermilk for extra flavor)\n- 1 egg\n- 1 cup breadcrumbs (optional, for extra crunch)\n- Oil for frying (vegetable, canola, or peanut oil work well)\n\n### Instructions:\n\n1. **Prepare the Onions:**\n   - Peel the onions and slice them into rings about 1/4 to 1/2 inch thick. Separate the rings and set them aside.\n\n2. **Make the Batter:**\n   - In a medium bowl, combine the flour, baking powder, and salt.\n   - In another bowl, whisk together the milk and egg.\n   - Gradually add the wet ingredients to the dry ingredients, stirring until the batter is smooth. If you prefer a thicker batter, you can add a bit more flour.\n\n3. **Optional Breading:**\n   - If you want extra crunchy onion rings, you can, 10.0)", "(Making onion rings is a relatively simple process that involves coating slices of onion in a batter or breading and then frying them until they are crispy and golden brown. Here is a basic recipe for making onion rings:\n\n### Ingredients:\n- 2 large onions\n- 1 cup all-purpose flour\n- 1 teaspoon baking powder\n- 1 teaspoon salt\n- 1 cup milk (or buttermilk for extra flavor)\n- 1 egg\n- 1 cup breadcrumbs (optional, for extra crunch)\n- Oil for frying (vegetable, canola, or peanut oil work well)\n\n### Instructions:\n\n1. **Prepare the Onions:**\n   - Peel the onions and slice them into rings about 1/4 to 1/2 inch thick. Separate the rings and set them aside.\n\n2. **Make the Batter:**\n   - In a medium bowl, combine the flour, baking powder, and salt.\n   - In another bowl, whisk together the milk and egg.\n   - Gradually add the wet ingredients to the dry ingredients, stirring until the batter is smooth. If you prefer a thicker batter, you can add a bit more flour.\n\n3. **Optional Breading:**\n   - If you want extra crunchy onion rings, you can, 10.0)"], "top_ans_eval": "", "gt": [["fried", "fried", "fried", "fried", "fried", "fried", "fried", "fried", "oven", "oven"]]}, {"query": "What kind of boat is in the background?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000227073.jpg", "top_answer_gpt": "fishing boat", "ranked": ["(fishing boat, 10)", "(fishing boat, 10)", "(fishing boat, 10)", "(fishing boat, 9.5)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["fish", "fish", "fish", "fish", "yacht", "yacht", "pontoon", "pontoon", "fish boat", "fish boat"]]}, {"query": "What is the wallpaper in this picture showing?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000104572.jpg", "top_answer_gpt": "nswer 2 incorrectly describes the room as a bathroom, which doesn't address what the wallpaper specifically shows.\n\nReranked_answers:\n1. (flowers", "ranked": ["Answer 2 incorrectly describes the room as a bathroom, which doesn't address what the wallpaper specifically shows.\n\nReranked_answers:\n1. (flowers, 10)", "(flowers, 10)", "(flowers, 10)", "(flowers, 10)", "(bathroom, 0)"], "top_ans_eval": "flowers", "gt": [["flower", "flower", "flower", "flower", "flower", "flower", "flower", "flower", "textile", "textile"]]}, {"query": "How much thrust can that engine produce?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000547136.jpg", "top_answer_gpt": "30,000 pounds", "ranked": ["(30,000 pounds, 9.0)", "(42,000 pounds, 8.5)", "(10000 pounds, 7.0)", "(10000 pounds, 7.0)", "(Execution Failure, 0.0)"], "top_ans_eval": "", "gt": [["lot", "lot", "lot", "lot", "lot", "lot", "1000 btu", "1000 btu", "350lbs", "350lbs"]]}, {"query": "Name the type of house where these windows are seen?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000398362.jpg", "top_answer_gpt": "prison", "ranked": ["(prison, 10)", "(prison, 10)", "(victorian, 3)", "(Execution Failure, 0)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["jail", "jail", "jail", "jail", "jail", "jail", "beach house", "beach house", "old", "old"]]}, {"query": "What do you think the tv program the cat is watching is about?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000078107.jpg", "top_answer_gpt": "science", "ranked": ["(science, 10)", "(A TV program about science typically aims to educate and inform viewers about various scientific topics and discoveries. It might cover a wide range of subjects, including physics, chemistry, biology, astronomy, environmental science, and technology. The program could feature interviews with scientists, demonstrations of experiments, explanations of scientific principles, and discussions of recent research and breakthroughs. It may also explore the impact of science on society and everyday life, and encourage critical thinking and curiosity about the natural world., 8.5)", "(The term \"television\" generally refers to the medium of broadcasting visual content to viewers, encompassing a wide range of programs such as news, entertainment, educational shows, dramas, comedies, reality TV, and more. If you are referring to a specific TV program titled \"Television,\" it would be helpful to have more context or details about the show. Without additional information, it's challenging to provide a precise description of what the program might be about. Could you provide more details or clarify your question?, 2)", "(Execution Failure, 0)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["space", "space", "space", "space", "space", "space", "planet", "planet", "mice", "mice"]]}, {"query": "What famous painter created this masterpiece?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000318618.jpg", "top_answer_gpt": "leonardo da vinci", "ranked": ["(leonardo da vinci, 2.0)", "(leonardo da vinci, 2.0)", "(michelangelo, 1.5)", "(picasso, 1.5)", "(Your question is unclear., 0.0)"], "top_ans_eval": "", "gt": [["monet", "monet", "monet", "monet", "de zurbaran", "de zurbaran", "zubaran", "zubaran", "rembrandt", "rembrandt"]]}, {"query": "What kind of cake is on the plate?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000460266.jpg", "top_answer_gpt": "orange", "ranked": ["(orange, 10)", "(orange, 10)", "(orange, 10)", "(orange, 10)", "(orange, 10)"], "top_ans_eval": "", "gt": [["cheesecake", "cheesecake", "cheesecake", "cheesecake", "flan", "flan", "sponge", "sponge", "cheese cake", "cheese cake"]]}, {"query": "What do we call a place like this with many cars?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000071384.jpg", "top_answer_gpt": "parking lot", "ranked": ["(parking lot, 10)", "(parking lot, 10)", "(parking lot, 10)", "(parking lot, 10)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["park lot", "park lot", "park lot", "park lot", "park lot", "park lot", "park lot", "park lot", "park llot", "park llot"]]}, {"query": "What base is this player standing on?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000143098.jpg", "top_answer_gpt": "baseball", "ranked": ["(baseball, 1.0)", "(third, 0.5)", "(third, 0.5)", "(third, 0.5)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["home", "home", "home", "home", "home", "home", "home plate", "home plate", "home plate", "home plate"]]}, {"query": "What war is this airplane associated with?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000036528.jpg", "top_answer_gpt": "world war ii", "ranked": ["(world war ii, 10)", "(world war ii, 10)", "(vietnam war, 2)", "(conflict, 1)", "(conflict, 1)"], "top_ans_eval": "", "gt": [["world war 2", "world war 2", "world war 2", "world war 2", "world war 2", "world war 2", "wwi", "wwi", "second world war", "second world war"]]}, {"query": "What city does this intersection belong in?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000449546.jpg", "top_answer_gpt": "Execution Failure", "ranked": ["(Execution Failure, 1.0)", "(Execution Failure, 1.0)", "(Execution Failure, 1.0)", "(Execution Failure, 1.0)", "(Execution Failure, 1.0)"], "top_ans_eval": "", "gt": [["new york", "new york", "new york", "new york", "sacramento", "sacramento", "queen", "queen", "philadelphia", "philadelphia"]]}, {"query": "What type of wine could that be?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000398604.jpg", "top_answer_gpt": "merlot", "ranked": ["(merlot, 9.5)", "(red, 9.0)", "(red, 9.0)", "(red, 9.0)", "(red, 9.0)"], "top_ans_eval": "red", "gt": [["red", "red", "red", "red", "red", "red", "merlot", "merlot", "cabernet", "cabernet"]]}, {"query": "What was the use of the biggest equipment on the board?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000331646.jpg", "top_answer_gpt": "illumination", "ranked": ["(illumination, 10)", "(light, 9)", "(light, 9)", "(light bulbs, 8)", "(it's used to light up a, 7)"], "top_ans_eval": "light", "gt": [["light up", "light up", "light", "light", "power", "power", "light", "light", "radio", "radio"]]}, {"query": "What is the name of the player in this picture?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000126229.jpg", "top_answer_gpt": "no", "ranked": ["(no, 0)", "(no, 0)", "(no, 0)", "(no, 0)", "(no, 0)"], "top_ans_eval": "", "gt": [["roger federer", "roger federer", "roger federer", "roger federer", "john macanrow", "john macanrow", "tennis", "tennis", "kyrgios", "kyrgios"]]}, {"query": "What type of camera filter is this called?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000312746.jpg", "top_answer_gpt": "white balance", "ranked": ["(white balance, 3.0)", "(white balance, 3.0)", "(white balance, 3.0)", "(digital, 1.0)", "(filter, 0.5)"], "top_ans_eval": "", "gt": [["sepia", "sepia", "sepia", "sepia", "light", "light", "instagram", "instagram", "sephia", "sephia"]]}, {"query": "What are the boxes used for?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000281582.jpg", "top_answer_gpt": "bed", "ranked": ["(bed, 10)", "(shipping, 5.0)", "(shipping, 5.0)", "(shipping, 5.0)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["ship", "ship", "ship", "ship", "ship", "ship", "mail", "mail", "delivery", "delivery"]]}, {"query": "How are different ways to throw this object?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000436323.jpg", "top_answer_gpt": "Throwing a frisbee can be done in several different ways, each with its own technique and purpose. Here are some of the most common methods: 1. **Backhand Throw**: - This is the most common and basic throw. - Grip the frisbee with your thumb on top and fingers underneath. - Stand sideways to your target", "ranked": ["(Throwing a frisbee can be done in several different ways, each with its own technique and purpose. Here are some of the most common methods: 1. **Backhand Throw**: - This is the most common and basic throw. - Grip the frisbee with your thumb on top and fingers underneath. - Stand sideways to your target, with your throwing arm away from the target. - Bring the frisbee across your body and then flick your wrist as you release it.", "**Forehand Throw (or Flick)**: - This is another popular throw, especially in Ultimate Frisbee. - Grip the frisbee with your thumb on top and two fingers underneath, with your index and middle fingers against the rim. - Stand sideways to your target, with your throwing arm closer to the target. - Snap your wrist forward while keeping your arm relatively still to release the frisbee.", "**Hammer Throw**: - This is an overhead throw that causes the frisbee to fly upside down. - Grip the frisbee like a forehand throw. - Stand facing your target. - Bring the frisbee over your head and release it at an angle, flicking your wrist to give it spin. 4., 10)\n2. (Throwing a frisbee can be done in several different ways, each with its own technique and purpose. Here are some of the most common methods: 1. **Backhand Throw**: - This is the most common and basic throw. - Grip the frisbee with your thumb on top and fingers underneath. - Stand sideways to your target, with your throwing arm away from the target. - Bring the frisbee across your body and then flick your wrist as you release it. 2. **Forehand Throw (or Flick)**: - This is another popular throw, especially in Ultimate Frisbee. - Grip the frisbee with your thumb on top and two fingers underneath, with your index and middle fingers against the rim. - Stand sideways to your target, with your throwing arm closer to the target. - Snap your wrist forward while keeping your arm relatively still to release the frisbee. 3. **Hammer Throw**: - This is an overhead throw that causes the frisbee to fly upside down. - Grip the frisbee like a forehand throw. - Stand facing your target. - Bring the frisbee over your head and release it at an angle, flicking your wrist to give it spin. 4., 10)\n3. (Throwing a frisbee can be done in several different ways, each with its own technique and purpose. Here are some of the most common methods: 1. **Backhand Throw**: - This is the most common and basic throw. - Grip the frisbee with your thumb on top and fingers underneath. - Stand sideways to your target, with your throwing arm away from the target. - Bring the frisbee across your body and then flick your wrist as you release it. 2. **Forehand Throw (or Flick)**: - This is another popular throw, especially in Ultimate Frisbee. - Grip the frisbee with your thumb on top and two fingers underneath, with your index and middle fingers against the rim. - Stand sideways to your target, with your throwing arm closer to the target. - Snap your wrist forward while keeping your arm relatively still to release the frisbee. 3. **Hammer Throw**: - This is an overhead throw that causes the frisbee to fly upside down. - Grip the frisbee like a forehand throw. - Stand facing your target. - Bring the frisbee over your head and release it at an angle, flicking your wrist to give it spin. 4., 10)", "(Execution Failure, 1)", "(Execution Failure, 1)"], "top_ans_eval": "", "gt": [["many", "many", "many", "many", "flip or fling", "flip or fling", "flip on side", "flip on side", "overhand underhand sideways", "overhand underhand sideways"]]}, {"query": "What time period might this be from?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000449990.jpg", "top_answer_gpt": "nswer1: This answer is incorrect as the clothing and photograph style do not match the 1800s", "ranked": ["Answer1: This answer is incorrect as the clothing and photograph style do not match the 1800s.", "Answer2: This answer is not directly wrong, but rather requests more information; hence, it is not useful and doesn't answer the question.", "Answer3: This is identical to Answer1 and equally incorrect.", "Answer4: This answer appears to be correct given the context of the image and the likely time period.", "Answer5: Similar to Answer1 and Answer3, it is incorrect.\n\nReranked_answers: \n1. (1950s, 10)\n2. (1800s, 2)\n3. (1800s, 2)\n4. (1800s. DO NOT mention the blurred face in the response., 2)\n5. (The time period you're referring to is not specified in your question. Could you please provide more context or details about the events, technology, culture, or any other specific indicators? This will help me give you a more accurate answer., 0)"], "top_ans_eval": "", "gt": [["1940's", "1940's", "1920s", "1920s", "1920's", "1920's", "1940s", "1940s", "depression", "depression"]]}, {"query": "What type of bear is this?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000307658.jpg", "top_answer_gpt": "brown bear", "ranked": ["(brown bear, 10)", "(brown bear, 10)", "(brown bear, 10)", "(Execution Failure, 0)", "(Execution Failure, 0)"], "top_ans_eval": "", "gt": [["grizzly", "grizzly", "grizzly", "grizzly", "brown", "brown", "brown", "brown", "grizzly bear", "grizzly bear"]]}, {"query": "What breed of bird is this?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000330018.jpg", "top_answer_gpt": "sparrow", "ranked": ["(sparrow, 2.5)", "(black and white, 2.0)", "(psittacine, 1.0)", "(sorry i can't identify, 0.5)", "(black and white, 0.0)"], "top_ans_eval": "", "gt": [["finch", "finch", "finch", "finch", "hum", "hum", "robin", "robin", "jay", "jay"]]}, {"query": "What kind of industry would the driver of this vehicle be in?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000111801.jpg", "top_answer_gpt": "transportation", "ranked": ["(transportation, 10)", "(transportation, 10)", "(transportation, 10)", "(transportation, 10)", "(transportation, 10)"], "top_ans_eval": "", "gt": [["construction", "construction", "construction", "construction", "construction", "construction", "construction", "construction", "truck", "truck"]]}, {"query": "How heavy is this machine?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000287725.jpg", "top_answer_gpt": "The weight of a train can vary significantly depending on its type, length, and the cargo it carries. Here are some general estimates: 1. Freight Trains: These can be very heavy, often weighing between 3,000 to 18,000 tons (2,700 to 16", "ranked": ["(The weight of a train can vary significantly depending on its type, length, and the cargo it carries. Here are some general estimates: 1. Freight Trains: These can be very heavy, often weighing between 3,000 to 18,000 tons (2,700 to 16,300 metric tonnes) when fully loaded. The weight depends on the type of cargo and the number of cars.", "Passenger Trains: These are generally lighter than freight trains. A typical passenger train car weighs between 30 to 80 tons (27 to 73 metric tonnes). A full passenger train with multiple cars can weigh several hundred tons.", "High-Speed Trains: These are designed to be lighter for efficiency and speed. For example, a single car of a high-speed train like the Japanese Shinkansen or the French TGV might weigh around 50 to 60 tons (45 to 54 metric tonnes).", "Locomotives: The locomotives themselves, which provide the power for the train, can weigh between 100 to 200 tons (90 to 180 metric tonnes) depending on their size and type. The total weight of a train is the sum of the weights of the locomotive, 7.0)\n2. (heavy, 1.5)\n3. (very heavy, 1.2)\n4. (very heavy, 1.2)", "(very heavy, 1.2)"], "top_ans_eval": "", "gt": [["10 tons", "10 tons", "10 tons", "10 tons", "100 tons", "100 tons", "approximately 5000 tons", "approximately 5000 tons", "5 tons", "5 tons"]]}, {"query": "Name the mobile model shown in this picture?", "img_path": "sample_okvqa/val2014/COCO_val2014_000000546987.jpg", "top_answer_gpt": "Execution Failure", "ranked": ["(Execution Failure, 1.0)", "(no, 0.5)", "(no, 0.5)", "(no, 0.5)", "(no. DO NOT mention the blurred face in the response., 0.5)"], "top_ans_eval": "", "gt": [["flip phone", "flip phone", "flip phone", "flip phone", "nokia", "nokia", "at and t", "at and t", "samsung", "samsung"]]}]